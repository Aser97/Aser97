> *“Tiny consistent steps compound into transformations that once seemed impossible.”*

---
### 🌐 Connect with Me

[![Email](https://img.shields.io/badge/Email-grey?logo=gmail)](mailto:lompoaser9@gmail.com)
[![Website](https://img.shields.io/badge/Website-0A66C2?logo=googlechrome&logoColor=white)](https://aser97.github.io/Blog/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?logo=huggingface&logoColor=black)](https://huggingface.co/AserLompo)
[![X (Twitter)](https://img.shields.io/badge/Twitter-black?logo=x)](https://x.com/aserlompo)
[![GitHub followers](https://img.shields.io/github/followers/Aser97?label=Follow&style=social)](https://github.com/Aser97)

---

### 🔬 Research

**[Impact of Class Imbalance on Gradient Descent Dynamics and Generalization (submission soon)](https://github.com/Aser97/Class-Imbalance-And-Gradient-Descent-Dynamics)**
We provide a mathematical analysis showing how class imbalance affects the generalization of a gradient-descent–trained softmax classifier. By explicitly characterizing the evolution of the logits under gradient descent, we prove that the each class converges at a rate proportional to $\frac{1}{\varepsilon h T}$ with $\varepsilon $ the class proportion in the dataset, $h$ the learning rate and $T$ the training steps. This theoretical predictions are confirmed by rigourous experiments in real-scenario settings. This article formalizes, in closed form, the empirical observation that imbalance implicitly biases optimization dynamics toward the majority class.

**[Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images (NeurIPS 2025 Workshop)](https://arxiv.org/pdf/2509.07966)**  
Visual reasoning over structured tabular data remains one of the hardest challenges for VLMs.  
Visual-TableQA introduces a large-scale multimodal dataset of **LaTeX-rendered tables** and **9 000 reasoning-intensive QA pairs**, produced for under $100 through a *multi-model collaborative generation pipeline*.  
The system combines *cross-model inspiration* and *LLM-jury filtering* to ensure diverse reasoning patterns and robust evaluation of visual reasoning performance.

**[Modality-Swap Distillation: Rendering Textual Reasoning into Visual Supervision (ICLR 2026 under review)](https://github.com/AI-4-Everyone/Visual-TableQA-v2)**  
A novel **modality-swap** approach for distilling reasoning ability from text-only LLMs into vision-language models.  
We show that textual reasoning can be *rendered* and re-used as synthetic visual supervision—improving cross-modal understanding at low cost.

**[Multi-Objective Representation for Numbers in Clinical Narratives (CoRR 2024)](https://doi.org/10.48550/arXiv.2405.18448)**  
Proposes **CamemBERT-Bio + LESA**, an efficient alternative to large-scale LLMs for modeling numerical magnitudes in medical text.  
Achieved +13 % F1 improvement while using less data and parameters.

**[Parametric Graph for Unimodal Ranking Bandit (ICML 2021)](https://hal.archives-ouvertes.fr/hal-03256621/)**  
Introduces a *parametric multi-armed bandit* algorithm for ranking under structured feedback graphs.  
Explores the link between **reinforcement learning** and **online ranking** theory.

---

### 🧩 Projects

#### 🧾 [Visual-TableQA Pipeline](https://github.com/AI-4-Everyone/Visual-TableQA-v2)  
Synthetic dataset generator for multimodal reasoning — creates 2 500 LaTeX tables + 9 000 QA pairs with LLM-jury quality control.

#### 🧬 [Multi-Objective Token Representation](https://github.com/sadc-lab/multiobjective_token_representation)  
Implements the **LESA + Xval** framework for numerical reasoning in CamemBERT-Bio.

#### ⚖️ [Optimal Transport for Color Transfer](https://github.com/Aser97/Optimal-Transport)  
Unbalanced OT visualizations for transferring color distributions between images.

#### ♟️ [Reinforcement Learning for Chess](https://github.com/Aser97/Chess)  
C++ implementation of **SARSA** and **Monte Carlo** algorithms that learn to play chess through self-play and Stockfish simulations.  
*(Reached ~1350 Elo after 1 hour of training.)*

#### 🔄 [CNN-Transformer](https://github.com/Aser97/CNN_T)  
Explores integrating **convolutional locality** into transformer layers for hybrid sequence modeling. *(Work in progress.)*

---

### 🧠 Tech Stack

**Languages:** Python · JavaScript · C++ · Bash · HTML/CSS  
**Frameworks:** PyTorch · Transformers · JAX · Hugging Face · APIs  
**Tools:** Docker · Paperspace
**Focus Areas:** Visual-Reasoning · Number Encoding · Reinforcement Learning · Applied Maths

---

### 🌱 Beyond Research

When I’m not building models, I:  
- Mentor students in **mathematics** and **AI fundamentals**  
- Compete in **chess tournaments** ♟️  
- Capture and edit **cinematic travel videos** 🎥  
